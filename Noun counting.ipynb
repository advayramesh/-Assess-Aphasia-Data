{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNdJkc3uPjapcba+HKEURgo"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2SyCKb4x6DlK","executionInfo":{"status":"ok","timestamp":1691042206046,"user_tz":420,"elapsed":2181,"user":{"displayName":"Shivani Ramesh","userId":"10960999651380156644"}},"outputId":"752b472a-3760-45b3-db22-e8b5e0a84ddb"},"outputs":[{"output_type":"stream","name":"stdout","text":["Noun: washing, Frequency: 1\n","Noun: overflow, Frequency: 1\n"]}],"source":["\n","\n","import spacy\n","from collections import Counter\n","\n","# Load the English tokenizer, tagger, parser, NER, and word vectors\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","def get_noun_frequency(text):\n","    # Process the text with spaCy\n","    doc = nlp(text)\n","\n","    # Create a Counter to store noun frequencies\n","    noun_counter = Counter()\n","\n","    # Iterate over tokens in the processed document\n","    for token in doc:\n","        # (pos == 'NN' or pos=='NNP' or pos=='NNS' or pos=='NNPS'\n","        if token.pos_ == \"NOUN\" or token.pos_ == \"PROPN\":\n","            noun_counter[token.text] += 1\n","\n","    return noun_counter\n","\n","# Example text\n","text = \"wash washing washed overflow\"\n","\n","# Get noun frequency using the function\n","noun_frequency = get_noun_frequency(text)\n","\n","# Print the noun frequency\n","for noun, frequency in noun_frequency.items():\n","    print(f\"Noun: {noun}, Frequency: {frequency}\")\n"]}]}